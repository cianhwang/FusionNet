{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "#from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(y, nb_channels, _strides = (1,1), _project_shortcut=False):\n",
    "    shortcut = y\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "    #y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "\n",
    "    y = layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "    #y = layers.BatchNormalization()()\n",
    "\n",
    "    if _project_shortcut or _strides != (1, 1):\n",
    "        shortcut = layers.Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    y = layers.add([shortcut, y])\n",
    "    #y = layers.LeakyReLU()(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net(x, nb_channels, _strides=(1, 1)):\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    shortcut = x\n",
    "    for _ in range(16):\n",
    "        x = res_block(x, 64)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    x = layers.add([shortcut, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, nb_channels, _strides=(1, 1)):\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    #x = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_net(y, nb_channels, _strides=(1, 1)):\n",
    "    #y = layers.Conv2D(64, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(y)\n",
    "    #y = layers.Conv2D(32, kernel_size=(3, 3), strides=_strides, padding='same', activation='relu')(y)\n",
    "    y = layers.Conv2D(3, kernel_size=(3, 3), strides=_strides, padding='same', activation='linear')(y)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_imgs(path, number, train_type):\n",
    "    result=np.empty((number, 64, 64, 3), dtype=\"float64\")\n",
    "    for i in range(number):\n",
    "        I = cv2.imread(path + \"{:04}_{}.jpeg\".format(i+1, train_type))\n",
    "        result[i, :, :, :] = I\n",
    "    return result/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inport training data\n",
    "dataNum = 1000\n",
    "x1_train = load_imgs(\"./blurImg/\", dataNum, 1)\n",
    "x2_train = load_imgs(\"./blurImg/\", dataNum, 2)\n",
    "y_train = load_imgs(\"./blurImg/\", dataNum, 0)\n",
    "\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "        \n",
    "def loss_wrapper(in_tensor1, in_tensor2):\n",
    "    def gaussian_blur(in_tensor):\n",
    "        # use large kernel to blur pred and in_tensor//\n",
    "        return\n",
    "        \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # or better implementation like fourier transformation\n",
    "        return K.binary_crossentropy(y_true, y_pred) + K.reduce_mean(K.square(gaussian_blur(y_pred)-gaussian_blur(in_tensor1)))\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 64, 64)   1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 64, 64, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 64, 64, 64)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 64, 64, 64)   0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 64)   36928       add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 64, 64, 64)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 64, 64, 64)   0           add_18[0][0]                     \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 64)   36928       add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 64, 64, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 64, 64, 64)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 64, 64, 64)   0           add_19[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 64)   36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 64, 64, 64)   36928       add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 64, 64, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 64, 64, 64)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 64, 64, 64)   0           add_20[0][0]                     \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 64)   36928       add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 64, 64, 64)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 64, 64, 64)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 64, 64, 64)   0           add_21[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 64, 64, 64)   36928       add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 64, 64, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 64, 64, 64)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 64, 64, 64)   0           add_22[0][0]                     \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 64, 64)   36928       add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 64, 64, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 64, 64, 64)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 64)   0           add_6[0][0]                      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 64, 64, 64)   0           add_23[0][0]                     \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 64, 64, 64)   36928       add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 64, 64, 64)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 64, 64, 64)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 64)   0           add_7[0][0]                      \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 64, 64, 64)   0           add_24[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 64)   36928       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 64, 64, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 64, 64, 64)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 64, 64)   0           add_8[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 64, 64, 64)   0           add_25[0][0]                     \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   36928       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 64)   36928       add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 64, 64, 64)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 64, 64, 64)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 64, 64)   0           add_9[0][0]                      \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 64, 64, 64)   0           add_26[0][0]                     \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   36928       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 64, 64)   36928       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 64, 64, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 64, 64, 64)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 64, 64)   0           add_10[0][0]                     \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 64, 64, 64)   0           add_27[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 64)   36928       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 64, 64, 64)   36928       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 64, 64, 64)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 64, 64, 64)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 64, 64)   0           add_11[0][0]                     \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 64, 64, 64)   0           add_28[0][0]                     \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 64, 64)   36928       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 64)   36928       add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 64, 64, 64)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 64, 64, 64)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 64, 64)   0           add_12[0][0]                     \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 64, 64, 64)   0           add_29[0][0]                     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 64)   36928       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 64, 64, 64)   36928       add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 64, 64, 64)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 64, 64, 64)   0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 64, 64, 64)   0           add_13[0][0]                     \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 64, 64, 64)   0           add_30[0][0]                     \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 64)   36928       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 64, 64, 64)   36928       add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 64, 64, 64)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 64, 64, 64)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 64, 64, 64)   0           add_14[0][0]                     \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 64, 64, 64)   0           add_31[0][0]                     \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 64, 64, 64)   36928       add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 64, 64, 64)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 64, 64, 64)   0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 64, 64, 64)   0           add_15[0][0]                     \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 64)   0           add_32[0][0]                     \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 64)   36928       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 64, 64)   36928       add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 64, 64, 64)   0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 64)   0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 128)  0           add_17[0][0]                     \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 64, 64, 3)    3459        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,444,291\n",
      "Trainable params: 2,444,291\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/anaconda2/envs/qian/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-827db5a370c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'generator.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "img_a = layers.Input(shape=(64, 64, 3))\n",
    "img_b = layers.Input(shape=(64, 64, 3))\n",
    "#feature_a = conv_net(img_a, 3)\n",
    "#feature_b = conv_net(img_b, 3)\n",
    "feature_a = res_net(img_a, 3)\n",
    "feature_b = res_net(img_b, 3)\n",
    "merge = layers.concatenate([feature_a, feature_b])\n",
    "aif = post_net(merge, 128)\n",
    "gen = Model(inputs = [img_a, img_b], output = [aif])\n",
    "gen.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gen.summary()\n",
    "plot_model(gen, to_file='generator.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1d279832bdd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg_batch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_batch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_batch2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgen_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_batch1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_batch2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    185\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/qian/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "Batch_size = 16\n",
    "nb_epoch = 100\n",
    "for epoch in range(nb_epoch):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[rand_idx, :, :, :]\n",
    "    gen.fit([img_batch1, img_batch2], y_batch)\n",
    "\n",
    "gen_img = gen.predict([img_batch1, img_batch2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_70 (Conv2D)           (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 64, 64, 1)         2305      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,471,298\n",
      "Trainable params: 2,471,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_fake = gen([img_a, img_b])\n",
    "dis = Sequential()\n",
    "dis.add(layers.Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "dis.add(layers.Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "dis.add(layers.Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "dis.add(layers.LeakyReLU())\n",
    "dis.add(layers.Conv2D(1, kernel_size=(3, 3), padding='same'))\n",
    "\n",
    "dis.add(layers.Flatten())\n",
    "dis.add(layers.Dense(512, activation='tanh'))\n",
    "dis.add(layers.Dense(1))\n",
    "dis.add(layers.Activation('sigmoid'))\n",
    "pred_prob = dis(image_fake)\n",
    "dis.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "dis.summary()\n",
    "plot_model(dis, to_file='discriminator.png')\n",
    "make_trainable(dis, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 64, 64, 3)    2444291     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1)            2471298     model_1[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,915,589\n",
      "Trainable params: 2,444,291\n",
      "Non-trainable params: 2,471,298\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "am = Model(inputs = [img_a, img_b], output = [pred_prob])\n",
    "am.summary()\n",
    "am.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "plot_model(am, to_file='adversary.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-train discriminate network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(losses[\"d\"], label='discriminitive loss')\n",
    "        plt.plot(losses[\"g\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:41<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train discriminator on generated images\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "Batch_size = 16\n",
    "nb_epoch = 100\n",
    "for epoch in tqdm(range(nb_epoch)):\n",
    "    rand_idx = np.random.randint(0, x1_train.shape[0], size = Batch_size)\n",
    "    img_batch1 = x1_train[rand_idx, :, :, :]\n",
    "    img_batch2 = x2_train[rand_idx, :, :, :]\n",
    "    y_batch = y_train[np.random.randint(0, y_train.shape[0], size = Batch_size), :, :, :]\n",
    "    #gen.fit([x1_train, x2_train], y_train)\n",
    "    gen_img = gen.predict([img_batch1, img_batch2])\n",
    "    X = np.concatenate((y_batch, gen_img))\n",
    "    y = np.zeros([2*Batch_size,])\n",
    "    y[0:Batch_size] = 1\n",
    "    y[Batch_size:] = 0\n",
    "    make_trainable(dis,True)\n",
    "    d_loss = dis.train_on_batch(X, y)\n",
    "    losses[\"d\"].append(d_loss)\n",
    "    \n",
    "    y2 = np.ones([Batch_size, ])\n",
    "    # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "    make_trainable(dis,False)\n",
    "    g_loss = am.train_on_batch([img_batch1, img_batch1], y2) #same batch or ???\n",
    "    losses[\"g\"].append(g_loss)\n",
    "    if epoch % 25 == 25 - 1:\n",
    "        plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
